apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: modelcar-pipeline
spec:
  params:
    - name: HUGGINGFACE_MODEL
      type: string
      description: "The Hugging Face model repository (e.g., ibm-granite/granite-3.2-2b-instruct)"
    - name: OCI_IMAGE
      type: string
      description: "The OCI image destination (e.g., quay.io/my-user/my-modelcar)"
    - name: HUGGINGFACE_ALLOW_PATTERNS
      type: string
      description: 'Optional array of file patterns to allow default: "*.safetensors", "*.json", "*.txt"'
      default: ""
    - name: COMPRESS_MODEL
      type: string
      description: "Whether to compress the model using llmcompressor (true/false)"
      default: "false"
  workspaces:
    - name: shared-workspace
    - name: quay-auth-workspace
  tasks:
    - name: cleanup-workspace
      taskSpec:
        workspaces:
          - name: shared-workspace
        steps:
          - name: cleanup
            image: quay.io/fedora/fedora:latest
            script: |
              #!/bin/sh
              set -e
              echo "Cleaning up workspace..."
              rm -rf /workspace/shared-workspace/*
              echo "Workspace cleanup complete!"
      workspaces:
        - name: shared-workspace
          workspace: shared-workspace
    - name: pull-model-from-huggingface
      taskSpec:
        workspaces:
          - name: shared-workspace
        params:
          - name: HUGGINGFACE_MODEL
          - name: HUGGINGFACE_ALLOW_PATTERNS
            type: string
            default: ""
        steps:
          - name: download-model
            image: quay.io/hayesphilip/huggingface-modelcar-builder:latest
            env:
              - name: HUGGINGFACE_TOKEN
                valueFrom:
                  secretKeyRef:
                    name: huggingface-secret
                    key: HUGGINGFACE_TOKEN
                    optional: true
            script: |
              #!/bin/sh
              set -e
              echo "Downloading model from Hugging Face..."
              mkdir -p /workspace/shared-workspace/model
              CMD="python download_model.py -m $(params.HUGGINGFACE_MODEL) -t /workspace/shared-workspace/model --token $HUGGINGFACE_TOKEN"
              if [ ! -z "$(params.HUGGINGFACE_ALLOW_PATTERNS)" ]; then
                CMD="$CMD --allow-patterns $(params.HUGGINGFACE_ALLOW_PATTERNS)"
              fi
              eval $CMD
              echo "Download complete!"
              if [ -d /workspace/shared-workspace/model/.cache ]; then
                echo "Removing cache"
                rm -r /workspace/shared-workspace/model/.cache
              fi
      params:
        - name: HUGGINGFACE_MODEL
          value: $(params.HUGGINGFACE_MODEL)
      workspaces:
        - name: shared-workspace
          workspace: shared-workspace
      runAfter:
        - cleanup-workspace
    - name: compress-model
      taskRef:
        name: compress-model
      params:
        - name: COMPRESS_MODEL
          value: $(params.COMPRESS_MODEL)
      workspaces:
        - name: shared-workspace
          workspace: shared-workspace
      runAfter:
        - pull-model-from-huggingface

    - name: build-and-push-modelcar
      taskSpec:
        workspaces:
          - name: shared-workspace
          - name: quay-auth-workspace
        params:
          - name: OCI_REGISTRY_SOURCE
          - name: OCI_REGISTRY_DESTINATION
        steps:
          - name: build-modelcar
            image: quay.io/fedora/fedora:latest
            script: |
              #!/bin/sh
              set -e
              echo "Installing dependencies..."
              dnf install -y golang git make python3-pip skopeo
              pip3 install poetry
              echo "Checking if OLOT already exists..."
              if [ -d "/workspace/shared-workspace/olot" ]; then
                echo "Removing existing OLOT directory..."
                rm -rf /workspace/shared-workspace/olot
              fi
              echo "Cloning and Installing OLOT..."
              git clone https://github.com/containers/olot.git /workspace/shared-workspace/olot
              cd /workspace/shared-workspace/olot
              make
              make install
              export PATH=$PATH:/usr/local/bin
              echo "OLOT installed successfully!"
              IMAGE_DIR=download
              MODEL_DIR=/workspace/shared-workspace/model
              echo "Downloading OCI image from $(params.OCI_REGISTRY_SOURCE)..."
              rm -rf $IMAGE_DIR
              skopeo copy --multi-arch all --remove-signatures \
                docker://$(params.OCI_REGISTRY_SOURCE) \
                oci:${IMAGE_DIR}:latest
              echo "Finding and appending model files to OCI image..."
              find $MODEL_DIR -name "*" -print0 | while IFS= read -r -d '' file; do
                echo "Adding $file to OCI image..."
                poetry run olot $IMAGE_DIR "$file"
              done
              echo "Pushing updated OCI image to $(params.OCI_REGISTRY_DESTINATION)..."
              skopeo copy --multi-arch all \
                --authfile /workspace/quay-auth-workspace/.dockerconfigjson \
                oci:${IMAGE_DIR}:latest \
                docker://$(params.OCI_REGISTRY_DESTINATION)
      params:
        - name: OCI_REGISTRY_SOURCE
          value: "registry.access.redhat.com/ubi9-micro@sha256:414cfa255ea10eaef4528a26d5618eb67cf487b635ee20f8f14b9317bfd6a4be"
        - name: OCI_REGISTRY_DESTINATION
          value: $(params.OCI_IMAGE)
      workspaces:
        - name: shared-workspace
          workspace: shared-workspace
        - name: quay-auth-workspace
          workspace: quay-auth-workspace
      runAfter:
        - compress-model
    - name: register-with-registry
      taskSpec:
        steps:
          - name: echo-register
            image: python:3.10-slim
            script: |
              #!/usr/bin/env python3
              print("register")
      runAfter:
        - build-and-push-modelcar
